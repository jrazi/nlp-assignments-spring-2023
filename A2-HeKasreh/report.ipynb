{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h3><center>تمرین دوم درس پردازش زبان‌های طبیعی</center></h3>\n",
    "<h4><center>چالش درست‌کردن هه کسره (گروه چهار)</center></h4>\n",
    "<table width='100%' style=\"border: none;\">\n",
    "    <tr style=\"border: none; text-align: center;\">\n",
    "        <td style=\"border: none;\"><h5>علیرضا بلال</h5></td>\n",
    "        <td style=\"border: none;\"><h5>زهرا رجالی</h5></td>\n",
    "        <td style=\"border: none;\"><h5>جواد راضی</h5></td>\n",
    "    </tr>\n",
    "</table>\n",
    "<h5 style=\"font-size: 16px;\"><center> ترم ۴۰۱۲ </center></h5>\n",
    "<br/>\n",
    "<hr/>\n",
    "<br/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h3>\n",
    "    خلاصه کارهای صورت‌گرفته\n",
    "</h3>\n",
    "<span>\n",
    "    در این تمرین، ماژولی را توسعه داده‌ایم که با دریافت یک متن فارسی به عنوان ورودی، ایرادات موسوم به «هکسره» آن را یافته، رفع کرده و متنی بدون خطاهای هکسره را برمی‌گرداند. \n",
    "</span>\n",
    "<br/>\n",
    "<span>\n",
    "    {بیان ایده برای نحوه یافتن غلط هکسره}\n",
    "</span>\n",
    "<span>\n",
    "    {ابزارها و پکیج‌های استفاده شده}\n",
    "</span>\n",
    "<span>\n",
    "    {نتایج دستیابی‌شده در تمرین}\n",
    "</span>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h3>\n",
    "    خطای هه کسره\n",
    "</h3>\n",
    "<div>\n",
    "    توضیحات کلی در مورد خطای هه کسره و قواعد تشخیصش \n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h3>\n",
    "    نصب پکیج‌ها و ابزارهای مورد نیاز\n",
    "</h3>\n",
    "<div>\n",
    "    توضیحات\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wapiti\n",
      "  Using cached wapiti-0.1.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [6 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\Javad\\AppData\\Local\\Temp\\pip-install-7p3ct5uk\\wapiti_e5ac4b9c34ce45a5913aef68248e3e2e\\setup.py\", line 28, in <module>\n",
      "      raise NotImplementedError(\"wapiti Python 3 support en route to your location\")\n",
      "  NotImplementedError: wapiti Python 3 support en route to your location\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import hazm\n",
    "except:\n",
    "    %pip install hazm\n",
    "    \n",
    "try: \n",
    "    import wapiti\n",
    "except: \n",
    "    %pip install wapiti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import Normalizer, WordTokenizer, POSTagger\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h3>\n",
    "    هم‌خوان‌سازی کد با کتاب‌خانه parsi-io\n",
    "</h3>\n",
    "<div>\n",
    "    توضیحات\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h3>\n",
    "    یافتن و تصحیح ایرادات هه کسره\n",
    "</h3>\n",
    "<div>\n",
    "</div>\n",
    "\n",
    "<h4>\n",
    "    بیان روش کلی\n",
    "</h4>\n",
    "<div>\n",
    "    توضیحات\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h3>\n",
    "    پیاده‌سازی کلاس HeKasraExtractor\n",
    "</h3>\n",
    "<div>\n",
    "    توضیحات\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeKasraCorrection: \n",
    "    def __init__(processed_text):\n",
    "        self.processed_text = processed_text\n",
    "        self.corrections = {\n",
    "            'correct': processed_text['raw_text'],\n",
    "        }\n",
    "    \n",
    "    def correct_token(self, invalid_token, corrected_token, str_index):\n",
    "        if invalid_token in self.corrections:\n",
    "            return\n",
    "        self.corrections[invalid_token] = [str_index, len(invalid_token)]\n",
    "        corrected_form = self.corrections['correct'][:str_index] + corrected_token + self.corrections['correct'][str_index+len(invalid_token):]\n",
    "        self.corrections['correct'] = corrected_form\n",
    "        return self.corrections\n",
    "    \n",
    "    def finalize(self):\n",
    "        return {\n",
    "            **self.processed_text,\n",
    "            'corrections': self.corrections,\n",
    "        }\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HeKasraExtractor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        normalizer = Normalizer()\n",
    "        normalized_text = normalizer.normalize(text)\n",
    "        tokenizer = WordTokenizer()\n",
    "        tokens = tokenizer.tokenize(normalized_text)\n",
    "        tagger = POSTagger(model=\"model/postagger.model\")\n",
    "        tagged_tokens = tagger.tag(tokens)\n",
    "        return {\n",
    "            'raw_text': text,\n",
    "            'normalized_text': normalized_text,\n",
    "            'tokens': tokens,\n",
    "            'pos_tags': tagged_tokens\n",
    "        }\n",
    "\n",
    "    # Define rules to identify \"He Kasrah\" grammar error\n",
    "    def find_he_kasra_errors(self, processed_text):\n",
    "        he_kasra_corrections = HeKasraCorrection(processed_text)\n",
    "        \n",
    "        # Add your rules based on POS tags and word patterns\n",
    "        # Example: if tag == 'N' and word.endswith('ه'): return True\n",
    "        return he_kasra_corrections.finalize()\n",
    "\n",
    "\n",
    "    def run(self, input_sentence):\n",
    "        processed = self.preprocess(input_sentence)\n",
    "        he_kasra_corrections = self.find_he_kasra_errors(processed)\n",
    "        return he_kasra_corrections['corrections']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wapiti'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15308\\3152472472.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhkasra_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15308\\3138294469.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPOSTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"model/postagger.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mtagged_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         return {\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hazm\\SequenceTagger.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, patterns, **options)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[1;32mfrom\u001b[0m \u001b[0mwapiti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wapiti'"
     ]
    }
   ],
   "source": [
    "hkasra_extractor = HeKasraExtractor()\n",
    "input_samples = ['کوروشه کبیر', 'حال من خوب است.', 'حاله من خوبه', 'من اگه کتابه تو رو داشتم', 'این دختره دیوانه', 'گل زیبا', 'گله زیبایی را تقدیم کردم']\n",
    "\n",
    "for sample in input_samples:\n",
    "    print(hkasra_extractor.preprocess(sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h3>\n",
    "    ارزیابی ماژول\n",
    "</h3>\n",
    "<div>\n",
    "    توضیحات\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h4>\n",
    "    خطای ه اضافه بجای نقش‌نمای اضافه\n",
    "</h4>\n",
    "<div>\n",
    "    توضیحات\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h4>\n",
    "    خطای عدم جای‌گذاری هکسره\n",
    "</h4>\n",
    "<div>\n",
    "    توضیحات\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
    "<h3>\n",
    "    تست عملکرد ماژول با تست‌های اتوماتیک\n",
    "</h3>\n",
    "<div>\n",
    "    توضیحات\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeHasraTests:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
