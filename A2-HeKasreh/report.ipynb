{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mYE-vgHGxwL"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
        "<h3><center>تمرین دوم درس پردازش زبان‌های طبیعی</center></h3>\n",
        "<h4><center>چالش درست‌کردن هه کسره (گروه چهار)</center></h4>\n",
        "<table width='100%' style=\"border: none;\">\n",
        "    <tr style=\"border: none; text-align: center;\">\n",
        "        <td style=\"border: none;\"><h5>علیرضا بلال</h5></td>\n",
        "        <td style=\"border: none;\"><h5>زهرا رجالی</h5></td>\n",
        "        <td style=\"border: none;\"><h5>جواد راضی</h5></td>\n",
        "    </tr>\n",
        "</table>\n",
        "<h5 style=\"font-size: 16px;\"><center> ترم ۴۰۱۲ </center></h5>\n",
        "<br/>\n",
        "<hr/>\n",
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0_30xV22oa6"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar', 'B Lotus', 'Calibri'\" size=3><div dir='rtl' align='justify'>\n",
        "<b>\n",
        "    فایل ژوپیتر این تمرین در کولب توسعه داده و تست شده‌است. ابزارهایی نظیر دادماتولز، به تجربه ما، در بعضی از محیط‌های محلی به خاطر یک سری تداخلات با نسخه پکیج‌ها در نصب به مشکل می‌خورند. اما این فایل هم در محیط کولب، هم با ایمیج داکر jupyter/datascience-notebook تست شده‌است و همه قطعه‌کدها خروجی مورد انتظار را می‌دهند. اگه در بازتولید خروجی بعضی سل‌ها مشکلی وجود داشت، ممنون می‌شویم در صورت امکان به ما اطلاع دهید تا فایل را در محیطی که قابل اجرا است، اجرا نموده و خروجی را نمایش دهیم. . \n",
        "</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RAmvwTvGxwO"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "#    **خطای هه کسره**\n",
        "در نوشتار فارسی، خطای \"ه‌کسره\" هنگامی به وجود می‌آید  که نشان کسره به درستی استفاده نشود.\n",
        "با اینکه صدای \"e\" در زبان فارسی دارای چندین نوع تکواژ است، اما برای نمایش آن در نوشتار دو نماد تکواژی وجود دارد. در مواقعی که به جای کسره (ـــِ) از \"ه/ـه\" استفاده شود یا برعکس، خطای گرامری هکسره به وجود می‌آید. در این تمرین، سرویسی را پیاده‌سازی کرده‌ایم که با دریافت یک متن فارسی، خطاهای «ه‌هکسره» آن را تشخیص داده و متن تصحیح شده را در پاسخ بر می‌گرداند. در ادامه گزارش، جزئیات پیاده‌سازی تمرین، و شیوه بکاررفته برای تشخیص خطای ه‌کسره شرح داده شده‌است. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzBffAvSGxwO"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "### **نصب پکیج‌ها و ابزارهای مورد نیاز**\n",
        "\n",
        "کتاب‌خانه‌های اصلی مورد استفاده در این تمرین، کتاب‌خانه‌های هضم و دادماتولز بوده‌اند. کتاب‌خانه هضم برای POS Tagging و دادماتولز برای بررسی شباهت کلمات استفاده شده‌است. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_ECGenxGxwO",
        "outputId": "61c594cc-fef7-4bd5-97fb-d15690611826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.7/316.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk==3.3->hazm) (1.16.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394488 sha256=2af089a7b5e9377e66854099ab22d233b6d3d13d12cd54901bde3557d80ab6b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/62/f6/88933dadcd64a1614894614aa68cf57c4b8e5256acb650b1f1\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp39-cp39-linux_x86_64.whl size=180368 sha256=37401722a8a171216ab8c57661ca2a4779b1ca9cba438e523dd6f0184286078d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/ff/82/9326b96f96f47472e02c453697b225813e4650c0ed4df2cd49\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dadmatools\n",
            "  Downloading dadmatools-1.5.2-py3-none-any.whl (862 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.6/862.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-transformers>=1.1.0\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hyperopt>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from dadmatools) (0.2.7)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from dadmatools) (3.5.1)\n",
            "Requirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from dadmatools) (4.3.1)\n",
            "Requirement already satisfied: gdown>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from dadmatools) (4.6.6)\n",
            "Collecting pyconll>=3.1.0\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Collecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.9/dist-packages (from dadmatools) (2.0.0+cu118)\n",
            "Collecting conllu\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting sklearn>=0.0\n",
            "  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.9.1\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.6 in /usr/local/lib/python3.9/dist-packages (from dadmatools) (0.8.10)\n",
            "Requirement already satisfied: folium>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from dadmatools) (0.14.0)\n",
            "Collecting Deprecated==1.2.6\n",
            "  Downloading Deprecated-1.2.6-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting supar==1.1.2\n",
            "  Downloading supar-1.1.2-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from dadmatools) (3.3)\n",
            "Collecting bpemb>=0.3.3\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Collecting NERDA\n",
            "  Downloading NERDA-1.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: h5py>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dadmatools) (3.8.0)\n",
            "Collecting py7zr>=0.17.2\n",
            "  Downloading py7zr-0.20.5-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/dist-packages (from Deprecated==1.2.6->dadmatools) (1.14.1)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stanza\n",
            "  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from bpemb>=0.3.3->dadmatools) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from bpemb>=0.3.3->dadmatools) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from bpemb>=0.3.3->dadmatools) (1.22.4)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.9/dist-packages (from folium>=0.2.1->dadmatools) (3.1.2)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from folium>=0.2.1->dadmatools) (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown>=4.3.1->dadmatools) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown>=4.3.1->dadmatools) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown>=4.3.1->dadmatools) (3.11.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim>=3.6.0->dadmatools) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim>=3.6.0->dadmatools) (1.10.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from hyperopt>=0.2.5->dadmatools) (0.18.3)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.9/dist-packages (from hyperopt>=0.2.5->dadmatools) (0.10.9.7)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from hyperopt>=0.2.5->dadmatools) (3.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from hyperopt>=0.2.5->dadmatools) (2.2.1)\n",
            "Collecting pyppmd<1.1.0,>=0.18.1\n",
            "  Downloading pyppmd-1.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp39-cp39-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.14.4\n",
            "  Downloading pyzstd-0.15.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.4/390.4 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1\n",
            "  Downloading inflate64-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0\n",
            "  Downloading pybcj-1.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from py7zr>=0.17.2->dadmatools) (5.9.4)\n",
            "Collecting texttable\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from pytorch-transformers>=1.1.0->dadmatools) (2022.10.31)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.114-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (1.10.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (23.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (67.6.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (2.4.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (1.1.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (0.7.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.12)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.0.0->dadmatools) (8.1.9)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.1->dadmatools) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.1->dadmatools) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.1->dadmatools) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.1->dadmatools) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.1->dadmatools) (3.25.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.9.1->dadmatools) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from NERDA->dadmatools) (1.5.3)\n",
            "Collecting progressbar\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2>=2.9->folium>=0.2.1->dadmatools) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (3.4)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.0.0->dadmatools) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.0.0->dadmatools) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.0.0->dadmatools) (8.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown>=4.3.1->dadmatools) (2.4)\n",
            "Collecting botocore<1.30.0,>=1.29.114\n",
            "  Downloading botocore-1.29.114-py3-none-any.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->NERDA->dadmatools) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->NERDA->dadmatools) (2.8.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->pytorch-transformers>=1.1.0->dadmatools) (1.2.0)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from stanza->supar==1.1.2->dadmatools) (3.20.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7.1->dadmatools) (1.3.0)\n",
            "Building wheels for collected packages: sklearn, progressbar, sacremoses, emoji\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post4-py3-none-any.whl size=2973 sha256=6df68dc5b799856848bbde7369b149c267de1014fcde259e5e902ea7370461ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/b2/a9/590d15767d34955f20a9a033e8db973b79cb5672d95790c0a9\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12080 sha256=bec734309e04e3ada1e5db64ac2c987679abacac0e4a45fe40fb4aebf88cbe03\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/d9/89/a3f31c76ff6d51dc3b1575628f59afe59e4ceae3f2748cd7ad\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=5d222bf51b76d532b2f918772405f86f3202b016f2d9cabb907305cf24f1b337\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=8d42a07938a3f51100b4336da42707ada9e49129f401d02375dcd6e17950b5c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/b8/0f/f580817231cbf59f6ade9fd132ff60ada1de9f7dc85521f857\n",
            "Successfully built sklearn progressbar sacremoses emoji\n",
            "Installing collected packages: tokenizers, tf-estimator-nightly, texttable, sklearn, sentencepiece, progressbar, brotli, segtok, sacremoses, pyzstd, pyppmd, pycryptodomex, pyconll, pybcj, multivolumefile, jmespath, inflate64, html2text, emoji, dill, Deprecated, conllu, py7zr, huggingface-hub, botocore, transformers, s3transfer, bpemb, boto3, stanza, supar, pytorch-transformers, NERDA, dadmatools\n",
            "Successfully installed Deprecated-1.2.6 NERDA-1.0.0 boto3-1.26.114 botocore-1.29.114 bpemb-0.3.4 brotli-1.0.9 conllu-4.5.2 dadmatools-1.5.2 dill-0.3.6 emoji-2.2.0 html2text-2020.1.16 huggingface-hub-0.13.4 inflate64-0.3.1 jmespath-1.0.1 multivolumefile-0.2.3 progressbar-2.5 py7zr-0.20.5 pybcj-1.0.1 pyconll-3.1.0 pycryptodomex-3.17 pyppmd-1.0.0 pytorch-transformers-1.2.0 pyzstd-0.15.6 s3transfer-0.6.0 sacremoses-0.0.53 segtok-1.5.11 sentencepiece-0.1.98 sklearn-0.0.post4 stanza-1.5.0 supar-1.1.2 texttable-1.6.7 tf-estimator-nightly-2.8.0.dev2021122109 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from fasttext) (67.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fasttext) (1.22.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp39-cp39-linux_x86_64.whl size=4395750 sha256=6a2ce68aa5bce31cbb9d127bacdeb88109ed7df98705767118d2f7f62c60e3ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/57/bc/1741406019061d5664914b070bd3e71f6244648732bc96109e\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.4\n"
          ]
        }
      ],
      "source": [
        "try: \n",
        "    import sklearn\n",
        "except:\n",
        "    %pip install -U scikit-learn numpy\n",
        "    \n",
        "try:\n",
        "    import hazm\n",
        "except:\n",
        "    %pip install hazm\n",
        "    \n",
        "try:\n",
        "    import dadmatools\n",
        "except:\n",
        "    %pip install dadmatools\n",
        "\n",
        "try:\n",
        "    import fasttext\n",
        "except:\n",
        "    %pip install fasttext\n",
        "\n",
        "try: \n",
        "    import wapiti\n",
        "except: \n",
        "    %pip install wapiti\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yku9-tEzGxwP"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "## **هم‌خوان‌سازی کد با کتاب‌خانه parsi-io**\n",
        "در پیاده‌سازی کد این تمرین،‌تلاش شده‌ که شیوه پیاده‌سازی سرویس، با الگوی پیاده‌سازی ابزار کتاب‌خانه parsi-io همگام باشد. \n",
        "`HeKasraExtractor`، کلاس\n",
        " اصلی این سرویس است که تلاش شده با چارچوبی متناسب با کتاب‌خانه یادشده توسعه داده شود. البته به علت رسیدن به ددلاین آپلود تمرین، فرصت برای پول ریکوئست به ریپازیتوری این کتاب‌خانه مهیا نشد. با تکمیل رعایت گایدلاین‌ها و قواعد کانتریبیوشن به ریپازیتوری پروژه یادشده، تلاش خواهیم کرد در آینده نزدیک به ریپازیتوری پارسی‌آی‌او پول‌ریکوئست دهیم. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzJeC323GxwQ"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "# **یافتن و تصحیح ایرادات هه کسره**\n",
        "<br>\n",
        "\n",
        "در نوشتار فارسی، خطای ه‌کسره با الگوهای خاصی رخ می‌دهد. به طور کلی،‌این الگوها تا حد زیادی قاعده‌مند می‌باشند و با وجود استثنائات، می‌توان خطاهای «ه‌کسره» را به چند دسته خاص تقسیم کرد.  \n",
        "در این [بلاگ‌پست](https://blog.irandargah.com/%D8%BA%D9%84%D8%B7%E2%80%8C%D9%87%D8%A7%DB%8C-%D9%86%DA%AF%D8%A7%D8%B1%D8%B4%DB%8C-%D9%88-%D8%A7%D9%85%D9%84%D8%A7%DB%8C%DB%8C%D8%8C-%D9%82%D8%A7%D8%AA%D9%84-%D8%A7%D8%B9%D8%AA%D8%A8%D8%A7%D8%B1/) \n",
        "به دسته‌بندی‌های مختلف خطای هکسره در زبان فارسی اشاره مختصر و مفیدی شده‌است. در این تمرین نیز پیاده‌سازی تشخیص هکسره را بر مبنای منابع از این دست انجام داده‌ایم. در ادامه به طور مختصر الگوهای رایج این خطای املایی شرح داده می‌شوند. \n",
        "\n",
        "#### الگوهای رایج غلط ه‌کسره\n",
        "1. **صفت و موصوف یا مضاف و مضافه‌الیه**  \n",
        "در ترکیبات وصفی و اضافی، باید بعد از موصوف یا مضاف الیه، از کسرهٔ اضافهٔ (ــِ) بین دو کلمهٔ مورد نظر استفاده کرد. بهتر است از \"ه\" یا \"ـه\" در این نوع ترکیبات استفاده نشود. \n",
        "    * **استثنا:‌ زمانی که تکواژ ه بخشی از واژه است**  \n",
        "    در موارد دیگری که ممکن است با خطاهای هکسره در فارسی مواجه شویم، حالتی وجود دارد که \"ه/ ـه\" به عنوان حرف اصلی در انتهای واژه ظاهر شده و جزئی از واژه است، و به این نوع از \"ه\" هم \"ه غیر ملفوظ\" گفته می‌شود. در این حالت‌ها، \"ه/ ـه\" نباید حذف شود و استفاده از کسره بجای آن مناسب نیست. \n",
        "<br><br>\n",
        "\n",
        "2. **تکواژ ه به عنوان معرفه‌ساز**  \n",
        "معرفه استفاده می‌شود. اسم‌های معرفه، اسامی هستند که برای شناسایی کسی یا چیزی به کار می‌روند. در صورتی که نویسنده در متن خود می‌خواهد به کسی یا چیزی اشاره کند که او را می‌شناسد، تکواژ \"ه\" به آخر کلمات اضافه می‌شود. استفاده از هکسره (-ِ) در این موارد کاملاً نادرست است. \n",
        "\n",
        "3. **تکواژ ه به جای فعل**  \n",
        "در زبان محاوره‌ای ما در برخی موارد به جای فعل \"است\" یا \"هست\"، از صدای \"e\" استفاده می‌کنیم. در این حالت‌ها باید از حرف \"ه\" به جای کسره استفاده کرد.\n",
        "همچنین در زبان محاوره، برای سوم شخص فعل‌ها، گاهی به جای پایان با \"ـَد\" از صدای \"e\" استفاده می‌شود. در چنین مواقعی نیز باید از حرف \"ه\" به جای کسره استفاده کرد.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEZx7BEjGxwQ"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "## **پیاده‌سازی سامانه تشخیص خطای هکسره**\n",
        "<br>\n",
        "\n",
        "#### کلاس `HeKasraCorrection`\n",
        "یک آبجکت از این کلاس، متنی که پیش‌پردازش‌های قبل روز آن انجام گرفته شده (به همراه متن خالص اولیه) را در خود دارد. متدهای آبجکت این کلاس، توسط متدهای پایپ‌لاین تشخیص هکسره صدا زده می‌شوند. اگر در پایپ‌لاین، متدی تشخیص داد که خطای هکسره وجود دارد، با تابع `vote_for_correction` این خطا به خطاهای بالقوه ارسال می‌شود.آرگومان ‍‍`order` در این تابع اولویت این تصحیح خطا را بیان می‌کند.  \n",
        "<br> \n",
        "تابع ‍‍‍`veto_correction` در این کلاس، اگر توسط کامپوننتی در پایپ‌لاین زده‌شد، خطاهای تشخیص داده‌شده توسط کامپوننت‌های قبلی پایپ‌لاین را وتو می‌کند. به عنوان مثال، در ترکیب «خانه زیبا» تابعی ابتدایی در پایپ‌لاین تشخیص خطای هکسره در این ترکیب وصفی می‌دهد، اما در ادامه پایپ‌لاین، تابعی تشخیص می‌دهد که ه، بخشی از خود کلمه «خانه» است و خطای هکسره محسوب نمی‌شود. بنابراین تشخیص خطای قبلی در اینجا وتو می‌گردد. \n",
        "<br>  \n",
        "\n",
        "تابع `finalize` نیز در انتها، پس از آنکه تمام ماژول‌های پایپ‌لاین رای خود را در خصوص خطاهای هکسره متن دادند، این خطاها را جمع‌آوری کرده، و به ترتیب اولویت آن‌ها را اعمال می‌کند. در نهایت نیز متن تصحیح شده ایجاد گردیده و خطاها و بازه مربوط به هر خط نیز مشخص می‌شود. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XUJIKyhzGxwQ"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "class HeKasraCorrection: \n",
        "    def __init__(self, processed_text):\n",
        "        self.processed_text = processed_text\n",
        "        self.corrections = {\n",
        "            'correct': processed_text['raw_text'],\n",
        "        }\n",
        "        self.correction_judgements = defaultdict(list)\n",
        "    \n",
        "    def vote_for_correction(self, invalid_token, corrected_token, str_index, order=10):\n",
        "        self.correction_judgements[str_index].append({\n",
        "            'invalid_token': invalid_token,\n",
        "            'corrected_token': corrected_token,\n",
        "            'str_index': str_index,\n",
        "            'order': order,\n",
        "        })\n",
        "        return self.correction_judgements[str_index]\n",
        "    \n",
        "    def veto_correction(self, already_correct_token, str_index):\n",
        "        self.correction_judgements[str_index].append({\n",
        "            'invalid_token': already_correct_token,\n",
        "            'corrected_token': already_correct_token,\n",
        "            'str_index': str_index,\n",
        "            'order': 0,\n",
        "        })\n",
        "        return self.correction_judgements[str_index]\n",
        " \n",
        "    def apply_correction_judgements(self, token, str_index):\n",
        "        # print('applying', token, str_index, self.correction_judgements)\n",
        "        judgements = self.correction_judgements[str_index]\n",
        "        # print('and now judgements', self.correction_judgements, self.correction_judgements.keys(), token, str_index)\n",
        "        if len(judgements) == 0:\n",
        "            return\n",
        "        \n",
        "        # print('judgements for token', token, str_index, judgements)\n",
        "        sorted_judgements = sorted(judgements, key=lambda x: x['order'])\n",
        "        prioritized_correction = sorted_judgements[0]\n",
        "        corrected_form = self.corrections['correct'][:str_index] + prioritized_correction['corrected_token'] + self.corrections['correct'][str_index+len(prioritized_correction['invalid_token']):]\n",
        "        self.corrections['correct'] = corrected_form\n",
        "        if token != prioritized_correction['corrected_token']:\n",
        "            self.corrections[prioritized_correction['invalid_token']] = [int(str_index), int(str_index)+len(prioritized_correction['invalid_token'])] \n",
        "              \n",
        "    def finalize(self):\n",
        "        for str_index in self.correction_judgements.copy().keys():\n",
        "            self.apply_correction_judgements(self.correction_judgements['invalid_token'], str_index)\n",
        "        if self.corrections['correct'] == self.processed_text['raw_text']:\n",
        "          self.corrections = {}\n",
        "        return {\n",
        "            **self.processed_text,\n",
        "            'correction': self.corrections,\n",
        "        }       "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYcisJiZX4i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7nUBayxdKNFe"
      },
      "outputs": [],
      "source": [
        "from dadmatools.embeddings import get_embedding\n",
        "# Some downloading, so separate the cell\n",
        "embeddings = get_embedding('glove-wiki')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBvOzYJK2obm"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "#### کلاس `HeKasraExtractor`\n",
        "این کلاس، در واقع کلاس اصلی سرویس است که با دریافت یک متن فارسی، خطاهای ه‌کسره آن را دریافت کرده و متن تصحیح‌شده را، به همراه بازه دقیق خطاها برمی‌گرداند. برای تشخیص ه‌کسره، تابع `run` این کلاس پایپ‌لاینی را اجرا می‌کند که شامل پیش‌پردازش‌هایی روی متن، annotate کردن آن و یافتن انواغ مختلف غلط ه‌کسره می‌باشد.  \n",
        "<br> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PK3TWkIUGxwQ"
      },
      "outputs": [],
      "source": [
        "from hazm import WordTokenizer, POSTagger, Normalizer\n",
        "import re\n",
        "\n",
        "normalizer = Normalizer()\n",
        "tokenizer = WordTokenizer()\n",
        "tagger = POSTagger(model=\"./model/postagger.model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-1Z9BD-U2obt"
      },
      "outputs": [],
      "source": [
        "\n",
        "class HeKasraExtractor:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def preprocess(self, text):\n",
        "        normalized_text = normalizer.normalize(text)\n",
        "        tokens = tokenizer.tokenize(normalized_text)\n",
        "        tagged_tokens = tagger.tag(tokens)\n",
        "\n",
        "        return {\n",
        "            'raw_text': text,\n",
        "            'normalized_text': normalized_text,\n",
        "            'tokens': tokens,\n",
        "            'pos_tags': tagged_tokens\n",
        "        }\n",
        "\n",
        "\n",
        "    def vote_n_adj_he_kasra(self, he_kasra_correction, processed_text):\n",
        "        he_kasra_pattern = r'\\b\\w*ه\\b'\n",
        "\n",
        "        # he_kasra_pattern = re.compile(r\"^[^ه]+[ِ]\\b\")\n",
        "\n",
        "        pos_pairs = zip(processed_text['pos_tags'][:-1], processed_text['pos_tags'][1:])\n",
        "\n",
        "        for ppair in pos_pairs:\n",
        "          p1, p2 = ppair\n",
        "          token_1, tag_1 = p1\n",
        "          token_2, tag_2 = p2\n",
        "          first_token_roles = ('N', 'Ne', 'PRO', 'AJ')\n",
        "          second_token_roles = ('N', 'Ne', 'AJ', 'PRO')\n",
        "          if tag_1 in first_token_roles and tag_2 in second_token_roles:\n",
        "              if re.match(he_kasra_pattern, token_1):\n",
        "                he_kasra_correction.vote_for_correction(token_1, token_1[:-1], processed_text['raw_text'].index(token_1))\n",
        "\n",
        "    def check_word_contains_he(self, word):\n",
        "        \n",
        "        normalized_word = normalizer.normalize(word)\n",
        "        if not normalized_word.endswith('ه'):\n",
        "            pass\n",
        "        \n",
        "        word_without_he = normalized_word[:-1]\n",
        "        try:\n",
        "          similarity = embeddings.similarity(word_without_he, normalized_word)\n",
        "          # Some arbitrary threshold, cause we're not a bunch of data scientists doing data science here. \n",
        "          return similarity > 0.8\n",
        "\n",
        "        except KeyError:\n",
        "          return False\n",
        "    \n",
        "    def veto_if_word_he_part_of_word(self, he_kasra_correction, processed_text):\n",
        "        he_kasra_pattern = r'\\b\\w*ه\\b'\n",
        "        for token, tag in processed_text['pos_tags']:\n",
        "            contains_he = self.check_word_contains_he(token)\n",
        "            if contains_he:\n",
        "                he_kasra_correction.veto_correction(token, processed_text['raw_text'].index(token))\n",
        "                                \n",
        "                                \n",
        "    def run(self, input_sentence):\n",
        "        prep_text = self.preprocess(input_sentence)\n",
        "        he_kasra_correction = HeKasraCorrection(prep_text)\n",
        "        \n",
        "        pipe = [\n",
        "            self.vote_n_adj_he_kasra, \n",
        "            self.veto_if_word_he_part_of_word,\n",
        "        ]\n",
        "        for func in pipe:\n",
        "            func(he_kasra_correction, prep_text)\n",
        "            \n",
        "        result = he_kasra_correction.finalize()\n",
        "        # print(result)\n",
        "        return result['correction']\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q8YyCiBIX3WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjLiuH3i2obw"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "\n",
        "## ارزیابی عملکرد سامانه \n",
        "قطعه کد زیر، با ایجاد یک اینستنس از کلاس ‍`HeKasraExtractor` برای تعدادی ورودی نمونه عملکرد آن را می‌سنجد. آبجکت خروجی تابع ران برای هر یک از ورودی‌ها در خروجی این سلول چاپ‌شده است. همان‌طور که مشاهده می‌شود، برای انوع خطاهای هکسره در ترکیبات وصفی و اضافی، ه معرفه‌ساز، ه به عنوان فعل و ...، کلاس پیاده‌سازی شده عملکرد صحیحی را دارد. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgM5R2UYGxwR",
        "outputId": "a14d911d-d755-4297-80da-795979c32d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Input: کوروشه کبیر\n",
            "Service Response {'correct': 'کوروش کبیر', 'کوروشه': [0, 6]}\n",
            "********\n",
            "Text Input: حال من خوب است.\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: حاله من خوبه\n",
            "Service Response {'correct': 'حال من خوبه', 'حاله': [0, 4]}\n",
            "********\n",
            "Text Input: من اگه کتابه تو رو داشتم\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: این دختره دیوانه کار دستمون داد\n",
            "Service Response {'correct': 'این دختر ددیوانکار دستمون داد', 'دختره': [4, 9], 'دیوانه': [10, 16]}\n",
            "********\n",
            "Text Input: گل زیبا\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: گله زیبایی را تقدیم کردم\n",
            "Service Response {'correct': 'گل زیبایی را تقدیم کردم', 'گله': [0, 3]}\n",
            "********\n",
            "Text Input: درختِ بزرگ\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: این کتاب خوبه\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: دستش خیلی تنده\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: فرشه خیلی قشنگ بود.\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: بسه دیگه خسته شدم.\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: خورشیده طلایی رنگ طلوع کرد.\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: یه سر به پیجِ ما بزنید\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: کیِ؟\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: اون خیابونه رو بستن جدیداً.\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: علی پرروئه\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: اصلاً نمی‌فهمم از چیه من خوشش اومد!\n",
            "Service Response {'correct': 'اصلاً نمی\\u200cفهمم از چی من خوشش اومد!', 'چیه': [18, 21]}\n",
            "********\n",
            "Text Input: اون اصلا غذا نمی­خورِ\n",
            "Service Response {}\n",
            "********\n",
            "Text Input: برکه‌ی مشهور\n",
            "Service Response {'correct': 'برکه\\u200c مشهور', 'برکه\\u200cی': [0, 6]}\n",
            "********\n",
            "Text Input: فرشته مرگ\n",
            "Service Response {'correct': 'فرشت مرگ', 'فرشته': [0, 5]}\n",
            "********\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "hkasra_extractor = HeKasraExtractor()\n",
        "input_samples = [\n",
        "    {\n",
        "      'text_input': 'کوروشه کبیر',\n",
        "      'expected_corrected_text': 'کوروش کبیر' ,\n",
        "      'correct_input': False\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'حال من خوب است.',\n",
        "      'expected_corrected_text': 'حال من خوب است.' ,\n",
        "      'correct_input': True\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'حاله من خوبه',\n",
        "      'expected_corrected_text': 'حال من خوبه' ,\n",
        "      'correct_input': False\n",
        "    },    {\n",
        "      'text_input': 'من اگه کتابه تو رو داشتم',\n",
        "      'expected_corrected_text': 'من اگه کتاب تو رو داشتم' ,\n",
        "      'correct_input': False\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'این دختره دیوانه کار دستمون داد',\n",
        "      'expected_corrected_text': 'این دختره دیوانه کار دستمون داد' ,\n",
        "      'correct_input': True\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'گل زیبا',\n",
        "      'expected_corrected_text': 'گل زیبا' ,\n",
        "      'correct_input': True\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'گله زیبایی را تقدیم کردم',\n",
        "      'expected_corrected_text': 'گل زیبایی را تقدیم کردم' ,\n",
        "      'correct_input': False\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'درختِ بزرگ',\n",
        "      'expected_corrected_text': 'درختِ بزرگ' ,\n",
        "      'correct_input': True\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'این کتاب خوبه',\n",
        "      'expected_corrected_text': 'این کتاب خوبه' ,\n",
        "      'correct_input': True\n",
        "    },    {\n",
        "      'text_input': 'دستش خیلی تنده',\n",
        "      'expected_corrected_text': 'دستش خیلی تنده' ,\n",
        "      'correct_input': True\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'فرشه خیلی قشنگ بود.',\n",
        "      'expected_corrected_text': 'فرشه خیلی قشنگ بود.' ,\n",
        "      'correct_input': True\n",
        "    },    {\n",
        "      'text_input': 'بسه دیگه خسته شدم.',\n",
        "      'expected_corrected_text': 'بسه دیگه خسته شدم.' ,\n",
        "      'correct_input': True\n",
        "    },    {\n",
        "      'text_input': 'خورشیده طلایی رنگ طلوع کرد.',\n",
        "      'expected_corrected_text': 'خورشید طلایی رنگ طلوع کرد.' ,\n",
        "      'correct_input': False\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'یه سر به پیجِ ما بزنید',\n",
        "      'expected_corrected_text': 'یه سر به پیجِ ما بزنید' ,\n",
        "      'correct_input': True\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'کیِ؟',\n",
        "      'expected_corrected_text': 'کی؟' ,\n",
        "      'correct_input': True\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'اون خیابونه رو بستن جدیداً.',\n",
        "      'expected_corrected_text': 'اون خیابونه رو بستن جدیداً.' ,\n",
        "      'correct_input': True\n",
        "    },    {\n",
        "      'text_input': 'علی پرروئه',\n",
        "      'expected_corrected_text': 'علی پرروئه' ,\n",
        "      'correct_input': True\n",
        "    },\n",
        "        {\n",
        "      'text_input': 'اصلاً نمی‌فهمم از چیه من خوشش اومد!',\n",
        "      'expected_corrected_text': 'اصلاً نمی‌فهمم از چی من خوشش اومد!' ,\n",
        "      'correct_input': False\n",
        "    },\n",
        "    {\n",
        "      'text_input': 'اون اصلا غذا نمی­خورِ',\n",
        "      'expected_corrected_text': 'اون اصلا غذا نمیخوره' ,\n",
        "      'correct_input': False\n",
        "    },\n",
        "    {\n",
        "      'text_input': 'برکه‌ی مشهور',\n",
        "      'expected_corrected_text': 'برکه‌ی مشهور' ,\n",
        "      'correct_input': True\n",
        "    },\n",
        "    {\n",
        "      'text_input': 'فرشته مرگ',\n",
        "      'expected_corrected_text': 'فرشته مرگ' ,\n",
        "      'correct_input': True\n",
        "    }\n",
        "]\n",
        "\n",
        "evaluation = np.zeros((len(input_samples), 5), dtype=object)\n",
        "for index, sample in enumerate(input_samples):\n",
        "  response = hkasra_extractor.run(sample['text_input'])\n",
        "  corrected_text = response['correct'] if 'correct' in response else sample['text_input']\n",
        "  print('Text Input: %s' % sample['text_input'])\n",
        "  print('Service Response', response)\n",
        "  print('********')\n",
        "  evaluation[index] = [sample['text_input'], sample['expected_corrected_text'], corrected_text, sample['expected_corrected_text'] == corrected_text, sample['text_input'] == sample['expected_corrected_text']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "\n",
        "## نتایج روی داده‌های تست \n",
        "قطعه کد زیر،‌ جدولی را چاپ می‌کند که به ازای هر ورودی، خروجی مورد انتظار (صحیح) و خروجی سرویس را نمایش می‌دهد. در سلول بعدی نیز دقت مدل در تشخیص وجود یا عدم وجود خطای هکسره سنجیده می‌گردد. "
      ],
      "metadata": {
        "id": "ND1TdfZ-g367"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "evaluation_df = pd.DataFrame(evaluation, columns=['Raw_Input', 'Expected_Output', 'Model_Output', 'Correct_Prediction', 'No_HeKasra_Error'])\n",
        "evaluation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "f_SfFLVxY-Jo",
        "outputId": "5e8ee974-54d0-4897-cb0d-0c29dc93b1a4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Raw_Input                     Expected_Output  \\\n",
              "0                           کوروشه کبیر                          کوروش کبیر   \n",
              "1                       حال من خوب است.                     حال من خوب است.   \n",
              "2                          حاله من خوبه                         حال من خوبه   \n",
              "3              من اگه کتابه تو رو داشتم             من اگه کتاب تو رو داشتم   \n",
              "4       این دختره دیوانه کار دستمون داد     این دختره دیوانه کار دستمون داد   \n",
              "5                               گل زیبا                             گل زیبا   \n",
              "6              گله زیبایی را تقدیم کردم             گل زیبایی را تقدیم کردم   \n",
              "7                            درختِ بزرگ                          درختِ بزرگ   \n",
              "8                         این کتاب خوبه                       این کتاب خوبه   \n",
              "9                        دستش خیلی تنده                      دستش خیلی تنده   \n",
              "10                  فرشه خیلی قشنگ بود.                 فرشه خیلی قشنگ بود.   \n",
              "11                   بسه دیگه خسته شدم.                  بسه دیگه خسته شدم.   \n",
              "12          خورشیده طلایی رنگ طلوع کرد.          خورشید طلایی رنگ طلوع کرد.   \n",
              "13               یه سر به پیجِ ما بزنید              یه سر به پیجِ ما بزنید   \n",
              "14                                 کیِ؟                                 کی؟   \n",
              "15          اون خیابونه رو بستن جدیداً.         اون خیابونه رو بستن جدیداً.   \n",
              "16                           علی پرروئه                          علی پرروئه   \n",
              "17  اصلاً نمی‌فهمم از چیه من خوشش اومد!  اصلاً نمی‌فهمم از چی من خوشش اومد!   \n",
              "18                اون اصلا غذا نمی­خورِ                اون اصلا غذا نمیخوره   \n",
              "19                         برکه‌ی مشهور                        برکه‌ی مشهور   \n",
              "20                            فرشته مرگ                           فرشته مرگ   \n",
              "\n",
              "                          Model_Output Correct_Prediction No_HeKasra_Error  \n",
              "0                           کوروش کبیر               True            False  \n",
              "1                      حال من خوب است.               True             True  \n",
              "2                          حال من خوبه               True            False  \n",
              "3             من اگه کتابه تو رو داشتم              False            False  \n",
              "4        این دختر ددیوانکار دستمون داد              False             True  \n",
              "5                              گل زیبا               True             True  \n",
              "6              گل زیبایی را تقدیم کردم               True            False  \n",
              "7                           درختِ بزرگ               True             True  \n",
              "8                        این کتاب خوبه               True             True  \n",
              "9                       دستش خیلی تنده               True             True  \n",
              "10                 فرشه خیلی قشنگ بود.               True             True  \n",
              "11                  بسه دیگه خسته شدم.               True             True  \n",
              "12         خورشیده طلایی رنگ طلوع کرد.              False            False  \n",
              "13              یه سر به پیجِ ما بزنید               True             True  \n",
              "14                                کیِ؟              False            False  \n",
              "15         اون خیابونه رو بستن جدیداً.               True             True  \n",
              "16                          علی پرروئه               True             True  \n",
              "17  اصلاً نمی‌فهمم از چی من خوشش اومد!               True            False  \n",
              "18               اون اصلا غذا نمی­خورِ              False            False  \n",
              "19                         برکه‌ مشهور              False             True  \n",
              "20                            فرشت مرگ              False             True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d897998a-2f9c-4b7c-b86f-ef0d7424959b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Raw_Input</th>\n",
              "      <th>Expected_Output</th>\n",
              "      <th>Model_Output</th>\n",
              "      <th>Correct_Prediction</th>\n",
              "      <th>No_HeKasra_Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>کوروشه کبیر</td>\n",
              "      <td>کوروش کبیر</td>\n",
              "      <td>کوروش کبیر</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>حال من خوب است.</td>\n",
              "      <td>حال من خوب است.</td>\n",
              "      <td>حال من خوب است.</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>حاله من خوبه</td>\n",
              "      <td>حال من خوبه</td>\n",
              "      <td>حال من خوبه</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>من اگه کتابه تو رو داشتم</td>\n",
              "      <td>من اگه کتاب تو رو داشتم</td>\n",
              "      <td>من اگه کتابه تو رو داشتم</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>این دختره دیوانه کار دستمون داد</td>\n",
              "      <td>این دختره دیوانه کار دستمون داد</td>\n",
              "      <td>این دختر ددیوانکار دستمون داد</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>گل زیبا</td>\n",
              "      <td>گل زیبا</td>\n",
              "      <td>گل زیبا</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>گله زیبایی را تقدیم کردم</td>\n",
              "      <td>گل زیبایی را تقدیم کردم</td>\n",
              "      <td>گل زیبایی را تقدیم کردم</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>درختِ بزرگ</td>\n",
              "      <td>درختِ بزرگ</td>\n",
              "      <td>درختِ بزرگ</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>این کتاب خوبه</td>\n",
              "      <td>این کتاب خوبه</td>\n",
              "      <td>این کتاب خوبه</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>دستش خیلی تنده</td>\n",
              "      <td>دستش خیلی تنده</td>\n",
              "      <td>دستش خیلی تنده</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>فرشه خیلی قشنگ بود.</td>\n",
              "      <td>فرشه خیلی قشنگ بود.</td>\n",
              "      <td>فرشه خیلی قشنگ بود.</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>بسه دیگه خسته شدم.</td>\n",
              "      <td>بسه دیگه خسته شدم.</td>\n",
              "      <td>بسه دیگه خسته شدم.</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>خورشیده طلایی رنگ طلوع کرد.</td>\n",
              "      <td>خورشید طلایی رنگ طلوع کرد.</td>\n",
              "      <td>خورشیده طلایی رنگ طلوع کرد.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>یه سر به پیجِ ما بزنید</td>\n",
              "      <td>یه سر به پیجِ ما بزنید</td>\n",
              "      <td>یه سر به پیجِ ما بزنید</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>کیِ؟</td>\n",
              "      <td>کی؟</td>\n",
              "      <td>کیِ؟</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>اون خیابونه رو بستن جدیداً.</td>\n",
              "      <td>اون خیابونه رو بستن جدیداً.</td>\n",
              "      <td>اون خیابونه رو بستن جدیداً.</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>علی پرروئه</td>\n",
              "      <td>علی پرروئه</td>\n",
              "      <td>علی پرروئه</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>اصلاً نمی‌فهمم از چیه من خوشش اومد!</td>\n",
              "      <td>اصلاً نمی‌فهمم از چی من خوشش اومد!</td>\n",
              "      <td>اصلاً نمی‌فهمم از چی من خوشش اومد!</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>اون اصلا غذا نمی­خورِ</td>\n",
              "      <td>اون اصلا غذا نمیخوره</td>\n",
              "      <td>اون اصلا غذا نمی­خورِ</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>برکه‌ی مشهور</td>\n",
              "      <td>برکه‌ی مشهور</td>\n",
              "      <td>برکه‌ مشهور</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>فرشته مرگ</td>\n",
              "      <td>فرشته مرگ</td>\n",
              "      <td>فرشت مرگ</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d897998a-2f9c-4b7c-b86f-ef0d7424959b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d897998a-2f9c-4b7c-b86f-ef0d7424959b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d897998a-2f9c-4b7c-b86f-ef0d7424959b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluation_df['Correct_Prediction'].mean()\n",
        "he_kasra_acc = evaluation_df.query('No_HeKasra_Error == False')['Correct_Prediction'].mean()\n",
        "he_kasra_free_acc = evaluation_df.query('No_HeKasra_Error == True')['Correct_Prediction'].mean()\n",
        "\n",
        "print(\"Model Accuracy: %1f\" % accuracy)\n",
        "print(\"Model Accuracy When HeKasra Error Occured: %1f\" % he_kasra_acc)\n",
        "print(\"Model Accuracy When Input Was HeKasra Error Free: %1f\" % he_kasra_free_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LGC0cMZbPGA",
        "outputId": "82e41415-4cab-460b-f44e-ddce72e31baf"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.666667\n",
            "Model Accuracy When HeKasra Error Occured: 0.500000\n",
            "Model Accuracy When Input Was HeKasra Error Free: 0.769231\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}