{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mYE-vgHGxwL"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir=rtl>\n",
        "<h3><center>تمرین دوم درس پردازش زبان‌های طبیعی</center></h3>\n",
        "<h4><center>چالش درست‌کردن هه کسره (گروه چهار)</center></h4>\n",
        "<table width='100%' style=\"border: none;\">\n",
        "    <tr style=\"border: none; text-align: center;\">\n",
        "        <td style=\"border: none;\"><h5>علیرضا بلال</h5></td>\n",
        "        <td style=\"border: none;\"><h5>زهرا رجالی</h5></td>\n",
        "        <td style=\"border: none;\"><h5>جواد راضی</h5></td>\n",
        "    </tr>\n",
        "</table>\n",
        "<h5 style=\"font-size: 16px;\"><center> ترم ۴۰۱۲ </center></h5>\n",
        "<br/>\n",
        "<hr/>\n",
        "<br/>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar', 'B Lotus', 'Calibri'\" size=3><div dir='rtl' align='justify'>\n",
        "<b>\n",
        "    فایل ژوپیتر این تمرین در کولب توسعه داده و تست شده‌است. ابزارهایی نظیر دادماتولز، به تجربه ما، در بعضی از محیط‌های محلی به خاطر یک سری تداخلات با نسخه پکیج‌ها در نصب به مشکل می‌خورند. اما این فایل هم در محیط کولب، هم با ایمیج داکر jupyter/datascience-notebook تست شده‌است و همه قطعه‌کدها خروجی مورد انتظار را می‌دهند. اگه در بازتولید خروجی بعضی سل‌ها مشکلی وجود داشت، ممنون می‌شویم در صورت امکان به ما اطلاع دهید تا فایل را در محیطی که قابل اجرا است، اجرا نموده و خروجی را نمایش دهیم. . \n",
        "</b>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6RAmvwTvGxwO"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "#    **خطای هه کسره**\n",
        "در نوشتار فارسی، خطای \"ه‌کسره\" هنگامی به وجود می‌آید  که نشان کسره به درستی استفاده نشود.\n",
        "با اینکه صدای \"e\" در زبان فارسی دارای چندین نوع تکواژ است، اما برای نمایش آن در نوشتار دو نماد تکواژی وجود دارد. در مواقعی که به جای کسره (ـــِ) از \"ه/ـه\" استفاده شود یا برعکس، خطای گرامری هکسره به وجود می‌آید. در این تمرین، سرویسی را پیاده‌سازی کرده‌ایم که با دریافت یک متن فارسی، خطاهای «ه‌هکسره» آن را تشخیص داده و متن تصحیح شده را در پاسخ بر می‌گرداند. در ادامه گزارش، جزئیات پیاده‌سازی تمرین، و شیوه بکاررفته برای تشخیص خطای ه‌کسره شرح داده شده‌است. \n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CzBffAvSGxwO"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "### **نصب پکیج‌ها و ابزارهای مورد نیاز**\n",
        "\n",
        "کتاب‌خانه‌های اصلی مورد استفاده در این تمرین، کتاب‌خانه‌های هضم و دادماتولز بوده‌اند. کتاب‌خانه هضم برای POS Tagging و دادماتولز برای بررسی شباهت کلمات استفاده شده‌است. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_ECGenxGxwO",
        "outputId": "dbfc1b33-2dae-4b2a-f8d5-dbe7cdc55f10"
      },
      "outputs": [],
      "source": [
        "try: \n",
        "    import sklearn\n",
        "except:\n",
        "    %pip install -U scikit-learn numpy\n",
        "    \n",
        "try:\n",
        "    import hazm\n",
        "except:\n",
        "    %pip install hazm\n",
        "    \n",
        "try:\n",
        "    import dadmatools\n",
        "except:\n",
        "    %pip install dadmatools\n",
        "\n",
        "try:\n",
        "    import fasttext\n",
        "except:\n",
        "    %pip install fasttext\n",
        "\n",
        "try: \n",
        "    import wapiti\n",
        "except: \n",
        "    %pip install wapiti\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yku9-tEzGxwP"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "## **هم‌خوان‌سازی کد با کتاب‌خانه parsi-io**\n",
        "در پیاده‌سازی کد این تمرین،‌تلاش شده‌ که شیوه پیاده‌سازی سرویس، با الگوی پیاده‌سازی ابزار کتاب‌خانه parsi-io همگام باشد. \n",
        "`HeKasraExtractor`، کلاس\n",
        " اصلی این سرویس است که تلاش شده با چارچوبی متناسب با کتاب‌خانه یادشده توسعه داده شود. البته به علت رسیدن به ددلاین آپلود تمرین، فرصت برای پول ریکوئست به ریپازیتوری این کتاب‌خانه مهیا نشد. با تکمیل رعایت گایدلاین‌ها و قواعد کانتریبیوشن به ریپازیتوری پروژه یادشده، تلاش خواهیم کرد در آینده نزدیک به ریپازیتوری پارسی‌آی‌او پول‌ریکوئست دهیم. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bzJeC323GxwQ"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "# **یافتن و تصحیح ایرادات هه کسره**\n",
        "<br>\n",
        "\n",
        "در نوشتار فارسی، خطای ه‌کسره با الگوهای خاصی رخ می‌دهد. به طور کلی،‌این الگوها تا حد زیادی قاعده‌مند می‌باشند و با وجود استثنائات، می‌توان خطاهای «ه‌کسره» را به چند دسته خاص تقسیم کرد.  \n",
        "در این [بلاگ‌پست](https://blog.irandargah.com/%D8%BA%D9%84%D8%B7%E2%80%8C%D9%87%D8%A7%DB%8C-%D9%86%DA%AF%D8%A7%D8%B1%D8%B4%DB%8C-%D9%88-%D8%A7%D9%85%D9%84%D8%A7%DB%8C%DB%8C%D8%8C-%D9%82%D8%A7%D8%AA%D9%84-%D8%A7%D8%B9%D8%AA%D8%A8%D8%A7%D8%B1/) \n",
        "به دسته‌بندی‌های مختلف خطای هکسره در زبان فارسی اشاره مختصر و مفیدی شده‌است. در این تمرین نیز پیاده‌سازی تشخیص هکسره را بر مبنای منابع از این دست انجام داده‌ایم. در ادامه به طور مختصر الگوهای رایج این خطای املایی شرح داده می‌شوند. \n",
        "\n",
        "#### الگوهای رایج غلط ه‌کسره\n",
        "1. **صفت و موصوف یا مضاف و مضافه‌الیه**  \n",
        "در ترکیبات وصفی و اضافی، باید بعد از موصوف یا مضاف الیه، از کسرهٔ اضافهٔ (ــِ) بین دو کلمهٔ مورد نظر استفاده کرد. بهتر است از \"ه\" یا \"ـه\" در این نوع ترکیبات استفاده نشود. \n",
        "    * **استثنا:‌ زمانی که تکواژ ه بخشی از واژه است**  \n",
        "    در موارد دیگری که ممکن است با خطاهای هکسره در فارسی مواجه شویم، حالتی وجود دارد که \"ه/ ـه\" به عنوان حرف اصلی در انتهای واژه ظاهر شده و جزئی از واژه است، و به این نوع از \"ه\" هم \"ه غیر ملفوظ\" گفته می‌شود. در این حالت‌ها، \"ه/ ـه\" نباید حذف شود و استفاده از کسره بجای آن مناسب نیست. \n",
        "<br><br>\n",
        "\n",
        "2. **تکواژ ه به عنوان معرفه‌ساز**  \n",
        "معرفه استفاده می‌شود. اسم‌های معرفه، اسامی هستند که برای شناسایی کسی یا چیزی به کار می‌روند. در صورتی که نویسنده در متن خود می‌خواهد به کسی یا چیزی اشاره کند که او را می‌شناسد، تکواژ \"ه\" به آخر کلمات اضافه می‌شود. استفاده از هکسره (-ِ) در این موارد کاملاً نادرست است. \n",
        "\n",
        "3. **تکواژ ه به جای فعل**  \n",
        "در زبان محاوره‌ای ما در برخی موارد به جای فعل \"است\" یا \"هست\"، از صدای \"e\" استفاده می‌کنیم. در این حالت‌ها باید از حرف \"ه\" به جای کسره استفاده کرد.\n",
        "همچنین در زبان محاوره، برای سوم شخص فعل‌ها، گاهی به جای پایان با \"ـَد\" از صدای \"e\" استفاده می‌شود. در چنین مواقعی نیز باید از حرف \"ه\" به جای کسره استفاده کرد.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QEZx7BEjGxwQ"
      },
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "## **پیاده‌سازی سامانه تشخیص خطای هکسره**\n",
        "<br>\n",
        "\n",
        "#### کلاس `HeKasraCorrection`\n",
        "یک آبجکت از این کلاس، متنی که پیش‌پردازش‌های قبل روز آن انجام گرفته شده (به همراه متن خالص اولیه) را در خود دارد. متدهای آبجکت این کلاس، توسط متدهای پایپ‌لاین تشخیص هکسره صدا زده می‌شوند. اگر در پایپ‌لاین، متدی تشخیص داد که خطای هکسره وجود دارد، با تابع `vote_for_correction` این خطا به خطاهای بالقوه ارسال می‌شود.آرگومان ‍‍`order` در این تابع اولویت این تصحیح خطا را بیان می‌کند.  \n",
        "<br> \n",
        "تابع ‍‍‍`veto_correction` در این کلاس، اگر توسط کامپوننتی در پایپ‌لاین زده‌شد، خطاهای تشخیص داده‌شده توسط کامپوننت‌های قبلی پایپ‌لاین را وتو می‌کند. به عنوان مثال، در ترکیب «خانه زیبا» تابعی ابتدایی در پایپ‌لاین تشخیص خطای هکسره در این ترکیب وصفی می‌دهد، اما در ادامه پایپ‌لاین، تابعی تشخیص می‌دهد که ه، بخشی از خود کلمه «خانه» است و خطای هکسره محسوب نمی‌شود. بنابراین تشخیص خطای قبلی در اینجا وتو می‌گردد. \n",
        "<br>  \n",
        "\n",
        "تابع `finalize` نیز در انتها، پس از آنکه تمام ماژول‌های پایپ‌لاین رای خود را در خصوص خطاهای هکسره متن دادند، این خطاها را جمع‌آوری کرده، و به ترتیب اولویت آن‌ها را اعمال می‌کند. در نهایت نیز متن تصحیح شده ایجاد گردیده و خطاها و بازه مربوط به هر خط نیز مشخص می‌شود. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XUJIKyhzGxwQ"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "class HeKasraCorrection: \n",
        "    def __init__(self, processed_text):\n",
        "        self.processed_text = processed_text\n",
        "        self.corrections = {\n",
        "            'correct': processed_text['raw_text'],\n",
        "        }\n",
        "        self.correction_judgements = defaultdict(list)\n",
        "    \n",
        "    def vote_for_correction(self, invalid_token, corrected_token, str_index, order=10):\n",
        "        self.correction_judgements[str_index].append({\n",
        "            'invalid_token': invalid_token,\n",
        "            'corrected_token': corrected_token,\n",
        "            'str_index': str_index,\n",
        "            'order': order,\n",
        "        })\n",
        "        return self.correction_judgements[str_index]\n",
        "    \n",
        "    def veto_correction(self, already_correct_token, str_index):\n",
        "        self.correction_judgements[str_index].append({\n",
        "            'invalid_token': already_correct_token,\n",
        "            'corrected_token': already_correct_token,\n",
        "            'str_index': str_index,\n",
        "            'order': 0,\n",
        "        })\n",
        "        return self.correction_judgements[str_index]\n",
        " \n",
        "    def apply_correction_judgements(self, token, str_index):\n",
        "        # print('applying', token, str_index, self.correction_judgements)\n",
        "        judgements = self.correction_judgements[str_index]\n",
        "        # print('and now judgements', self.correction_judgements, self.correction_judgements.keys(), token, str_index)\n",
        "        if len(judgements) == 0:\n",
        "            return\n",
        "        \n",
        "        # print('judgements for token', token, str_index, judgements)\n",
        "        sorted_judgements = sorted(judgements, key=lambda x: x['order'])\n",
        "        prioritized_correction = sorted_judgements[0]\n",
        "        corrected_form = self.corrections['correct'][:str_index] + prioritized_correction['corrected_token'] + self.corrections['correct'][str_index+len(prioritized_correction['invalid_token']):]\n",
        "        self.corrections['correct'] = corrected_form\n",
        "        if token != prioritized_correction['corrected_token']:\n",
        "            self.corrections[prioritized_correction['invalid_token']] = [int(str_index), int(str_index)+len(prioritized_correction['invalid_token'])] \n",
        "              \n",
        "    def finalize(self):\n",
        "        for str_index in self.correction_judgements.copy().keys():\n",
        "            self.apply_correction_judgements(self.correction_judgements['invalid_token'], str_index)\n",
        "        if self.corrections['correct'] == self.processed_text['raw_text']:\n",
        "          self.corrections = {}\n",
        "        return {\n",
        "            **self.processed_text,\n",
        "            'correction': self.corrections,\n",
        "        }       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7nUBayxdKNFe"
      },
      "outputs": [],
      "source": [
        "from dadmatools.embeddings import get_embedding\n",
        "# Some downloading, so separate the cell\n",
        "embeddings = get_embedding('glove-wiki')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "#### کلاس `HeKasraExtractor`\n",
        "این کلاس، در واقع کلاس اصلی سرویس است که با دریافت یک متن فارسی، خطاهای ه‌کسره آن را دریافت کرده و متن تصحیح‌شده را، به همراه بازه دقیق خطاها برمی‌گرداند. برای تشخیص ه‌کسره، تابع `run` این کلاس پایپ‌لاینی را اجرا می‌کند که شامل پیش‌پردازش‌هایی روی متن، annotate کردن آن و یافتن انواغ مختلف غلط ه‌کسره می‌باشد.  \n",
        "<br> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PK3TWkIUGxwQ"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        }
      ],
      "source": [
        "from hazm import WordTokenizer, POSTagger, Normalizer\n",
        "import re\n",
        "\n",
        "normalizer = Normalizer()\n",
        "tokenizer = WordTokenizer()\n",
        "tagger = POSTagger(model=\"model/postagger.model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class HeKasraExtractor:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def preprocess(self, text):\n",
        "        normalized_text = normalizer.normalize(text)\n",
        "        tokens = tokenizer.tokenize(normalized_text)\n",
        "        tagged_tokens = tagger.tag(tokens)\n",
        "\n",
        "        return {\n",
        "            'raw_text': text,\n",
        "            'normalized_text': normalized_text,\n",
        "            'tokens': tokens,\n",
        "            'pos_tags': tagged_tokens\n",
        "        }\n",
        "\n",
        "\n",
        "    def vote_n_adj_he_kasra(self, he_kasra_correction, processed_text):\n",
        "        he_kasra_pattern = r'\\b\\w*ه\\b'\n",
        "\n",
        "        # he_kasra_pattern = re.compile(r\"^[^ه]+[ِ]\\b\")\n",
        "\n",
        "        pos_pairs = zip(processed_text['pos_tags'][:-1], processed_text['pos_tags'][1:])\n",
        "\n",
        "        for ppair in pos_pairs:\n",
        "          p1, p2 = ppair\n",
        "          token_1, tag_1 = p1\n",
        "          token_2, tag_2 = p2\n",
        "          first_token_roles = ('N', 'Ne', 'PRO', 'AJ')\n",
        "          second_token_roles = ('N', 'Ne', 'AJ', 'PRO')\n",
        "          if tag_1 in first_token_roles and tag_2 in second_token_roles:\n",
        "              if re.match(he_kasra_pattern, token_1):\n",
        "                he_kasra_correction.vote_for_correction(token_1, token_1[:-1], processed_text['raw_text'].index(token_1))\n",
        "\n",
        "    def check_word_contains_he(self, word):\n",
        "        \n",
        "        normalized_word = normalizer.normalize(word)\n",
        "        if not normalized_word.endswith('ه'):\n",
        "            pass\n",
        "        \n",
        "        word_without_he = normalized_word[:-1]\n",
        "        try:\n",
        "          similarity = embeddings.similarity(word_without_he, normalized_word)\n",
        "          # Some arbitrary threshold, cause we're not a bunch of data scientists doing data science here. \n",
        "          return similarity > 0.8\n",
        "\n",
        "        except KeyError:\n",
        "          return False\n",
        "    \n",
        "    def veto_if_word_he_part_of_word(self, he_kasra_correction, processed_text):\n",
        "        he_kasra_pattern = r'\\b\\w*ه\\b'\n",
        "        for token, tag in processed_text['pos_tags']:\n",
        "            contains_he = self.check_word_contains_he(token)\n",
        "            if contains_he:\n",
        "                he_kasra_correction.veto_correction(token, processed_text['raw_text'].index(token))\n",
        "                                \n",
        "                                \n",
        "    def run(self, input_sentence):\n",
        "        prep_text = self.preprocess(input_sentence)\n",
        "        he_kasra_correction = HeKasraCorrection(prep_text)\n",
        "        \n",
        "        pipe = [\n",
        "            self.vote_n_adj_he_kasra, \n",
        "            self.veto_if_word_he_part_of_word,\n",
        "        ]\n",
        "        for func in pipe:\n",
        "            func(he_kasra_correction, prep_text)\n",
        "            \n",
        "        result = he_kasra_correction.finalize()\n",
        "        # print(result)\n",
        "        return result['correction']\n",
        "    \n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font face=\"'vazirmatn', 'Vazir', 'B Nazanin', 'XB Zar'\" size=4><div dir='rtl' align='justify'>\n",
        "\n",
        "#### بررسی عملکرد سامانه \n",
        "قطعه کد زیر، با ایجاد یک اینستنس از کلاس ‍`HeKasraExtractor` برای تعدادی ورودی نمونه عملکرد آن را می‌سنجد. آبجکت خروجی تابع ران برای هر یک از ورودی‌ها در خروجی این سلول چاپ‌شده است. همان‌طور که مشاهده می‌شود، برای انوع خطاهای هکسره در ترکیبات وصفی و اضافی، ه معرفه‌ساز، ه به عنوان فعل و ...، کلاس پیاده‌سازی شده عملکرد صحیحی را دارد. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgM5R2UYGxwR",
        "outputId": "fafba004-cd29-4fc5-c00b-fececa553381"
      },
      "outputs": [],
      "source": [
        "hkasra_extractor = HeKasraExtractor()\n",
        "input_samples = [\n",
        "  'کوروشه کبیر', \n",
        "  'حال من خوب است.', \n",
        "  'حاله من خوبه', \n",
        "  'من اگه کتابه تو رو داشتم', \n",
        "  'این دختره دیوانه', \n",
        "  'گل زیبا',\n",
        "  'گله زیبایی را تقدیم کردم'\n",
        "]\n",
        "\n",
        "for sample in input_samples:\n",
        "  res = hkasra_extractor.run(sample)\n",
        "  print(res.items())\n",
        "  # print(hkasra_extractor.run(sample))\n",
        "    # print(hkasra_extractor.preprocess(sample))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
